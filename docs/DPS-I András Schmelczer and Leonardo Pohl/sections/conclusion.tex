\section{Conclusion}

Even though the authors did not disclose the number of repetitions of their experiments, we found that this paper is of very high quality. We also have to note that the authors provided no information about the time of day the experiment or any other external factors which could have affected the experiment, especially, when running on AWS hardware.

Zaharia et al. described the experiments with a high level of detail, and they also explained their outcomes and consequences formidably well. The graphs created from the experiments understandably showed the results, and the authors made good use of all charts and tables pointing out essential features. We reproduced a macrobenchmark with an IO-heavy workload. The naive fair scheduler was not significantly different from the fair scheduler with delay scheduling in their experiment.

In our repeated experiments, we came to almost the same conclusions as the authors did when conducting the experiments giving us reason to believe that the results in the paper are reproducible.

Overall, we conclude that the authors did an excellent job presenting delay scheduling and showing through experimenting with different realistic and intentionally straining experiments. These evaluations showed how their introduced scheduling method fares in real-world applications compared with the system in place at that time. The conducted experiments, their consequences, and interpretations were explained and presented in an in-depth but understandable manner.
